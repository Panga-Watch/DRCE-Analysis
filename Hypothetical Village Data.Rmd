---
title: "Hypothetical Village Data"
author: "Gage Clawson"
date: "1/16/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mefa)
library(survival)
library(utils)
library(cowplot)
library(WDI)
library(beepr)

set.seed(6969)

```

```{r}
# load necessary packages for importing the function
library(RCurl)
 
# import the function from repository
url_robust <- "https://raw.githubusercontent.com/IsidoreBeautrelet/economictheoryblog/master/robust_summary.R"
eval(parse(text = getURL(url_robust, ssl.verifypeer = FALSE)))
```

Puerto San Carlos; Based off of Jumbo Squid Fishery.
Paper: [Socioeconomic Diagnosis of the 2010 Jumbo Squid Artisanal Fishery near Magdalena Bay, Baja California Sur, Mexico](http://www.scielo.org.mx/scielo.php?script=sci_arttext&pid=S0188-88972014000100002)

Statistics: 
 - Population 5538 (2010 census data)
 - Artisanal Fisheries employ about 50% of the working population. 
 - 1800 fishing permits for jumbo squid 
   - "almost all of our respondents engage in other fisheries when jumbo squid are not present"
   - Assume that there are 1800 fishers in Puerto San Carlos. 
 - Average age is 34 years with a range of 18 to 78. 
 - No formal education (34%); formal (middle or high school; 30% + 33% = 63%); classify the remaining as higher (3%)
 - average of $11,090 Mexican Pesos each month (+/- $1,000 USD per month)
 - Assume biggest problem for the fishery is IUU. 
 - 8% did not have fishing communication technology on their boat. 

```{r}
wtpmin <- -5.35

fishtech <- c(0,1)
psc_prob_fishtech <- c(0.08, 0.92)
rank_one <- c("corruption", "pollution", "weather", "iuu")
education <- c("no_formal", "formal", "higher")
psc_prob_edu <- c(0.34, 0.63, 0.03)

gdp_prop_PSC_1 <- read_csv("int/log_log_variables.csv") %>%
  filter(community == "PSC") 

gdp_prop_population <- length(gdp_prop_PSC_1$survey_id)

gdp_prop_prob <- gdp_prop_PSC_1 %>%
  group_by(gdp_prop) %>%
  summarise(n = length(gdp_prop)) %>% 
  mutate(prob = n/gdp_prop_population) %>%
  mutate(percent = round(prob*100))
gdp_prop_prob$percent[[1]] <- 5

gdp_prop_prob_new <- gdp_prop_prob %>%
  mutate(new_prob = percent/100) 


gdp_prop_PSC <- c(gdp_prop_prob_new$gdp_prop)
gdp_prop_prob_PSC <- c(gdp_prop_prob_new$new_prob)

psc <- data.frame(
                  fishtech = sample(rep(fishtech, round(1800*psc_prob_fishtech))),
                  education = sample(rep(education, round(1800*psc_prob_edu))),
                  rank_one = "iuu",
                  gdp_prop = sample(rep(gdp_prop_PSC, round(1800*gdp_prop_prob_PSC)))
                  )


sos <- c(0,1)
info <- c(0,1)
own <- c("1", "2", "3", "4")

packages <- expand.grid(sos = sos,info = info, own= own)


psc_all_packages <- merge(psc, packages)

#write.csv(psc_all_packages, "hypo_village_data/PuertoSanCarlos/PuertoSanCarlos.csv", row.names = FALSE)

## load in specific model 
load("output/int_15.rda")

psc_all_packages_lm15 <- psc_all_packages %>%
  dplyr::select(-gdp_prop)

psc_predict <- data.frame(psc_all_packages_lm15, int_15_wtp = predict(int_15, newdata = psc_all_packages)) 

packages <- read_csv("raw/packages.csv")  %>%
  filter(package <= 16) %>%
  mutate(sos = ifelse(sos==2,1,0), info=ifelse(info==2,0,1)) %>%
  mutate(own = factor(own))

psc_predict_packages <- left_join(psc_predict, packages) 

#write.csv(psc_predict_packages, "hypo_village_data/PuertoSanCarlos/PuertoSanCarlos_predictions.csv", row.names = FALSE)


## lets try it a different way, without comparing the dollar values... I think we get same result, just a bit harder to interpret

dollar_values <- seq(-3, 8, by = 0.01)

# try_psc<-psc_predict_packages %>% 
#   #filter(regression_type == "interval") %>% 
#   group_by(package, int_15_wtp) %>% 
#   tally() %>% 
#   mutate(prop=n/sum(n)) %>% 
#   arrange(desc(int_15_wtp)) %>% 
#   mutate(prop_sum = cumsum(prop)) 
# 
# try_psc %>% 
#   #filter(package == 1) %>%
#   ggplot( aes(x = int_15_wtp, y = prop_sum, color = factor(package))) +
#   geom_step() +
#   scale_x_continuous(breaks = seq(-4, 6, by = 1)) +
#   theme_bw() + 
#   labs(x = "Cost to Fisher ($/month)", y = "Proportion of Population to Opt In")

```


```{r}

## Make a list of data frames for each package combination. 
my_data_psc <- list()
for (i in unique(psc_predict_packages$package)) {
    my_data_psc[[i]] <- filter(psc_predict_packages, package == i)
}

#save(my_data_psc, file="hypo_village_data/PuertoSanCarlos/psc_predict_by_package.RData") ## save this list to read back in for graphs.


```

```{r}

# read list in to begin making data usable to graph
load("hypo_village_data/PuertoSanCarlos/psc_predict_by_package.RData")

mean(my_data_psc[[1]]$int_15_wtp)

test <- my_data_psc[[1]] ## this is psc with package 1 predictions. Can do the same for all 16 packages.

sim_total <- nrow(my_data_psc[[1]])
dollar_values <- seq(-3, 8, by = 0.01)

## Interval Model Graph Data ##
system.time(new_data_int <- lapply(my_data_psc, function(x) {
  
  graph_df <- x %>%
  merge(dollar_values) %>%
  mutate(opt_in_int = ifelse(int_15_wtp > y, 1, 0 )) %>% ## if the wtp is greater than payment value, then they will opt in, otherwise, opt out
  arrange(opt_in_int)

group_df_opt_in <- graph_df %>%
  group_by(y, opt_in_int) %>%
  tally() %>%
  filter(opt_in_int == 1) %>% ## filter for all opt ins...
  mutate(perc = n/sim_total,
         opt_in_out = "Opt In") %>% ##384 total scenarios
  ungroup()

  
}))
beep()

#save(new_data_int, file="hypo_village_data/PuertoSanCarlos/psc_predict_int_graphdata.RData")

```


## GRAPHS!

```{r}

## plot interval regression acceptance rate ##
load(file="hypo_village_data/PuertoSanCarlos/psc_predict_int_graphdata.RData")


int_all <- bind_rows(new_data_int, .id = "package") %>%
  merge(packages) %>%
  rename(
         "opt" = "opt_in_int") %>%
  mutate(regression_type = "interval",
         package = as.integer(package))


PSC_all_predictions <- int_all


## Save the final dataframe

#write.csv(PSC_all_predictions, "hypo_village_data/PuertoSanCarlos/psc_all_predictions_FINAL.csv", row.names = FALSE)

## save all of the graphs 


PSC_all_predictions <- read_csv("hypo_village_data/PuertoSanCarlos/psc_all_predictions_FINAL.csv")

for(i in unique(PSC_all_predictions$package)){

  p <- ggplot(data = filter(PSC_all_predictions, package == i), aes(x = y, y = perc)) +
    geom_point() + 
    geom_line() +
    labs(title = "Puerto San Carlos", x = "Fisher Payment ($/month)", y = "Percent Opt In VMS Program", caption = paste("Package", i)) +
    theme_classic() +
    scale_x_continuous(breaks = seq(-3,8, 1)) +
    scale_y_continuous(breaks = seq(0,1, 0.1))

  save_plot(p, file = paste0("hypo_village_data/PuertoSanCarlos/graphs/", "PSC_interval" ,"_", i, ".png"))
  
}


graph_data_psc <- PSC_all_predictions %>%
  filter(opt_in_out == "Opt In", package %in% c(8,11), regression_type == "interval")

  
  ggplot(graph_data_psc, aes(x = y, y = perc, color = factor(sos))) + 
    geom_line() +
    theme_bw() +
    labs() +
    labs(x = "Cost to Fisher ($ per month)", y = "Proportion of Population to Opt In") +
        scale_x_continuous(breaks = c(-3,-2, -1, 0, 1, 2, 3, 4, 5, 6)) +
    scale_color_manual(values = c("goldenrod1", "lightseagreen"), name = "SOS Functionality", labels = c("No", "Yes")) +
    scale_y_continuous(breaks = seq(0,1,0.2))

```

Pepela Indonesia
Paper: 

Statistics: 
 - Population 370
 - No formal education (0.04864865); formal (0.9432432); classify the remaining as higher (0.008108108)
 - Assume biggest problem for the fishery is weather. 
 - 30% did not have fishing technology on their boat. 

```{r}
wtpmin <- -5.35

fishtech <- c(0,1)
pepela_prob_fishtech <- c(0.3, 0.7)
# rank_one <- c("corruption", "pollution", "weather", "iuu")
education <- c("no_formal", "formal", "higher")
pepela_prob_edu <- c(0.04864865, 0.9432432, 0.008108108)

pepela <- data.frame(
                  fishtech = sample(rep(fishtech, round(370*pepela_prob_fishtech))),
                  education = sample(rep(education, round(370*pepela_prob_edu))),
                  rank_one = "weather"
                  )


sos <- c(0,1)
info <- c(0,1)
own <- c("1", "2", "3", "4")

packages <- expand.grid(sos = sos,info = info, own= own)

pepela_all_packages <- merge(pepela, packages)

#write.csv(pepela_all_packages, "hypo_village_data/Pepela/pepela.csv", row.names = FALSE)

## load in specific model 
load("output/int_15.rda")

pepela_predict <- data.frame(pepela_all_packages, int_15_wtp = predict(int_15, newdata = pepela_all_packages)) ## if you want to add predictions from another model, just tack it onto the end. Now we can filter for a technology and make graphs based off of that. 

packages <- read_csv("raw/packages.csv")  %>%
  filter(package <= 16) %>%
  mutate(sos = ifelse(sos==2,1,0), info=ifelse(info==2,0,1)) %>%
  mutate(own = factor(own))

pepela_predict_packages <- left_join(pepela_predict, packages) 
#write.csv(pepela_predict_packages, "hypo_village_data/Pepela/pepela_predictions.csv", row.names = FALSE)

## lets try it a different way, without comparing the dollar values... I think we get same result, just a bit harder to interpret
try_pepela <-pepela_predict_packages %>% s
  group_by(package, int_15_wtp) %>% 
  tally() %>% 
  mutate(prop=n/sum(n)) %>% 
  arrange(desc(int_15_wtp)) %>% 
  mutate(prop_sum = cumsum(prop)) 

try_pepela %>% 
  #filter(package == 11) %>%
  ggplot( aes(x = int_15_wtp, y = prop_sum, color = factor(package))) +
  geom_step() +
  scale_x_continuous(breaks = seq(-4, 6, by = 1)) +
  theme_bw() + 
  labs(x = "Cost to Fisher ($/month)", y = "Proportion of Population to Opt In")


```


```{r}

## Make a list of data frames for each package combination. 
my_data_pepela <- list()
for (i in unique(pepela_predict_packages$package)) {
    my_data_pepela[[i]] <- filter(pepela_predict_packages, package == i)
}

#save(my_data_pepela, file="hypo_village_data/Pepela/pepela_predict_by_package.RData") ## save this list to read back in for graphs.
```

```{r}

# read list in to begin making data usable to graph
load("hypo_village_data/Pepela/pepela_predict_by_package.RData")

mean(my_data_pepela[[1]]$int_15_wtp)

test <- my_data_pepela[[1]] ## this is psc with package 1 predictions. Can do the same for all 16 packages.

sim_total <- nrow(my_data_pepela[[1]])
dollar_values <- seq(-3, 8, by = 0.01)

## Interval Model Graph Data ##
system.time(new_data_int <- lapply(my_data_pepela, function(x) {
  
  graph_df <- x %>%
  merge(dollar_values) %>%
  mutate(opt_in_int = ifelse(int_15_wtp > y, 1, 0 )) %>% ## if the wtp is greater than payment value, then they will opt in, otherwise, opt out
  arrange(opt_in_int)

group_df_opt_in <- graph_df %>%
  group_by(y, opt_in_int) %>%
  tally() %>%
  filter(opt_in_int == 1) %>% ## filter for all opt ins...
  mutate(perc = n/sim_total,
         opt_in_out = "Opt In") %>% ##384 total scenarios
  ungroup()

}))
beep()

save(new_data_int, file="hypo_village_data/Pepela/pepela_predict_int_graphdata.RData")

```

## GRAPHS!
```{r}

## plot interval regression acceptance rate ##
load(file="hypo_village_data/Pepela/pepela_predict_int_graphdata.RData")


int_all <- bind_rows(new_data_int, .id = "package") %>%
  merge(packages) %>%
  rename(
         "opt" = "opt_in_int") %>%
  mutate(regression_type = "interval",
         package = as.integer(package))


Pepela_all_predictions <- int_all


## Save the final dataframe

#write.csv(Pepela_all_predictions, "hypo_village_data/Pepela/pepela_all_predictions_FINAL.csv", row.names = FALSE)

## save all of the graphs 


Pepela_all_predictions <- read_csv("hypo_village_data/Pepela/pepela_all_predictions_FINAL.csv")

for(i in unique(Pepela_all_predictions$package)){

  p <- ggplot(data = filter(Pepela_all_predictions, package == i), aes(x = y, y = perc)) +
    geom_point() + 
    geom_line() +
    labs(title = "Pepela", x = "Fisher Payment ($/month)", y = "Percent Opt In VMS Program", caption = paste("Package", i)) +
    theme_classic() +
    scale_x_continuous(breaks = seq(-3,8, 1)) +
    scale_y_continuous(breaks = seq(0,1, 0.1))

  save_plot(p, file = paste0("hypo_village_data/Pepela/graphs/",  "Pepela_interval_", i, ".png"))
}

graph_data_pepela <- Pepela_all_predictions %>%
  filter(opt_in_out == "Opt In", package %in% c(8,11), regression_type == "interval")
  
  ggplot(graph_data_pepela, aes(x = y, y = perc, color = factor(sos))) + 
    geom_line() +
    theme_bw() +
    labs(x = "Cost to Fisher ($ per month)", y = "Proportion of Population to Opt In") +
        scale_x_continuous(breaks = c(-3,-2, -1, 0, 1, 2,3 ,4)) +
    scale_color_manual(values = c("goldenrod1", "lightseagreen"), name = "SOS Functionality", labels = c("No", "Yes"))  +
    scale_y_continuous(breaks = seq(0,1, 0.2))

```


WKB data

```{r}
survey_data <- read_csv("int/log_log_variables.csv") %>%
  select(country, community, education, fishtech, rank_one)

WKB <- survey_data %>%
  filter(community == "WKB") %>%
  select(education, fishtech, rank_one)

sos <- c(0,1)
info <- c(0,1)
own <- c("1", "2", "3", "4")

packages <- expand.grid(sos = sos,info = info, own= own)


wkb_all_packages <- merge(WKB, packages)

write.csv(wkb_all_packages, "hypo_village_data/WKB/WKB.csv", row.names = FALSE)

## load in specific model 
load("output/int_15.rda")

wkb_predict <- data.frame(wkb_all_packages, int_15_wtp = predict(int_15, newdata = wkb_all_packages)) 

packages <- read_csv("raw/packages.csv")  %>%
  filter(package <= 16) %>%
  mutate(sos = ifelse(sos==2,1,0), info=ifelse(info==2,0,1)) %>%
  mutate(own = factor(own))

wkb_predict_packages <- left_join(wkb_predict, packages) 

write.csv(wkb_predict_packages, "hypo_village_data/WKB/WKB_predictions.csv", row.names = FALSE)


## lets try it a different way, without comparing the dollar values... I think we get same result, just a bit harder to interpret

dollar_values <- seq(-3, 8, by = 0.01)

# try_psc<-psc_predict_packages %>% 
#   #filter(regression_type == "interval") %>% 
#   group_by(package, int_15_wtp) %>% 
#   tally() %>% 
#   mutate(prop=n/sum(n)) %>% 
#   arrange(desc(int_15_wtp)) %>% 
#   mutate(prop_sum = cumsum(prop)) 
# 
# try_psc %>% 
#   #filter(package == 1) %>%
#   ggplot( aes(x = int_15_wtp, y = prop_sum, color = factor(package))) +
#   geom_step() +
#   scale_x_continuous(breaks = seq(-4, 6, by = 1)) +
#   theme_bw() + 
#   labs(x = "Cost to Fisher ($/month)", y = "Proportion of Population to Opt In")

```


```{r}

## Make a list of data frames for each package combination. 
my_data_wkb <- list()
for (i in unique(wkb_predict_packages$package)) {
    my_data_wkb[[i]] <- filter(wkb_predict_packages, package == i)
}

save(my_data_wkb, file="hypo_village_data/WKB/WKB_predict_by_package.RData") ## save this list to read back in for graphs.


```

```{r}

# read list in to begin making data usable to graph
load("hypo_village_data/WKB/WKB_predict_by_package.RData")

mean(my_data_wkb[[1]]$int_15_wtp)

test <- my_data_wkb[[1]] ## this is psc with package 1 predictions. Can do the same for all 16 packages.

sim_total <- nrow(my_data_wkb[[1]])
dollar_values <- seq(-3, 8, by = 0.01)

## Interval Model Graph Data ##
system.time(new_data_int <- lapply(my_data_wkb, function(x) {
  
  graph_df <- x %>%
  merge(dollar_values) %>%
  mutate(opt_in_int = ifelse(int_15_wtp > y, 1, 0 )) %>% ## if the wtp is greater than payment value, then they will opt in, otherwise, opt out
  arrange(opt_in_int)

group_df_opt_in <- graph_df %>%
  group_by(y, opt_in_int) %>%
  tally() %>%
  filter(opt_in_int == 1) %>% ## filter for all opt ins...
  mutate(perc = n/sim_total,
         opt_in_out = "Opt In") %>% ##384 total scenarios
  ungroup()

  
}))
beep()

#tests <- new_data_int[[1]]
save(new_data_int, file="hypo_village_data/WKB/WKB_predict_int_graphdata.RData")

load(file="hypo_village_data/WKB/WKB_predict_int_graphdata.RData")


int_all <- bind_rows(new_data_int, .id = "package") %>%
  merge(packages) %>%
  rename(
         "opt" = "opt_in_int") %>%
  mutate(regression_type = "interval",
         package = as.integer(package))


WKB_all_predictions <- int_all


## Save the final dataframe

write.csv(WKB_all_predictions, "hypo_village_data/WKB/WKB_all_predictions_FINAL.csv", row.names = FALSE)
```
